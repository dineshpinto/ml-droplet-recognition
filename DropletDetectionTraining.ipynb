{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ce6f8-07c8-4ce8-8bef-a5d138d22371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipympl\n",
    "\n",
    "import image_handler as handler\n",
    "import test_data_generator as test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a066d65f-05cc-4503-a60f-f106ff9e5289",
   "metadata": {},
   "source": [
    "# Standard CV2 circle detection (Hough Circle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6fcfbb-6344-4ba0-bc42-3fddc711e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(cv2.imread(os.path.join(\"testing_data\", \"image.png\")), cv2.COLOR_BGR2GRAY)\n",
    "output = img.copy()\n",
    "\n",
    "circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 20, param1=50, param2=30, minRadius=40, maxRadius=60)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.round(circles[0, :]).astype(\"int\")\n",
    "    for (x, y, r) in circles:\n",
    "        cv2.circle(output, center=(x, y), radius=r, color=(0, 255, 0), thickness=4)\n",
    "        cv2.rectangle(output, pt1=(x-5, y-5), pt2=(x+5, y+5), color=(0, 128, 255), thickness=-1)\n",
    "    \n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
    "ax[0].imshow(img, cmap='gray')\n",
    "ax[1].imshow(output, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15102149-898d-4c63-b2db-dcb5a963c9a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41baa8d-bfc1-486f-a827-472c1cc8b4be",
   "metadata": {},
   "source": [
    "### Sample test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da8b26-b922-4a24-9a10-419f1b62bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "img_shape = (200, 200, 3)\n",
    "img, label = create_data_sample(10, img_shape[0], img_shape[1])\n",
    "\n",
    "show_sample(img, label)\n",
    "print(img.shape, label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80254f59-3ca8-4a4d-ad63-227af613a087",
   "metadata": {},
   "source": [
    "### Batch test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae1daa-a03b-4f8c-a2a0-3b1096031c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = []\n",
    "label_batch = []\n",
    "\n",
    "for idx in range(1):\n",
    "    img, label  = create_data_sample(10, img_shape[0], img_shape[1])\n",
    "    img_batch.append(img)\n",
    "    label_batch.append(label)\n",
    "    \n",
    "img_batch = np.array(img_batch)\n",
    "label_batch = np.array(label_batch)\n",
    "\n",
    "print(img_batch.shape, label_batch.shape)\n",
    "show_batch(img_batch, label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8627be-cf0a-495e-9132-0a5c74f9ae27",
   "metadata": {},
   "source": [
    "# Real data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a4c03-adc0-46f3-b832-e225ed8a24bf",
   "metadata": {},
   "source": [
    "### Sample real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e664df-2ba0-47a4-a2a2-08643a2c7705",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (187, 249, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6bb77-ac69-48ed-a19d-15841fdad53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 46\n",
    "images = sorted(os.listdir(\"training_data\"))\n",
    "print(images[i])\n",
    "raw, img, label = handler.load_image(os.path.join(\"training_data\", images[i]), (145, 100, 0.04), overlay=True)\n",
    "\n",
    "print(img_shape)\n",
    "\n",
    "handler.show_sample(img, label)\n",
    "# plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59ec0bf-abdb-47dd-8ea8-df7fb15087bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b2711f-acb8-452a-97c4-4a09808849e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(raw)\n",
    "# fig.savefig(os.path.join(\"results\", \"real_data_raw.png\"), dpi=300, bbox_inches='tight')\n",
    "\n",
    "# fig.savefig(os.path.join(\"results\", \"real_data_processed.png\"), dpi=300, bbox_inches='tight')\n",
    "# plt.close(\"all\")'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f618fcd-8157-4fa7-8c8c-42e11a576323",
   "metadata": {},
   "source": [
    "### Batch real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ba11e-4835-4288-a42f-1ea06878cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from droplet_labels import droplet_labels\n",
    "img_batch, label_batch = handler.load_images_from_folder(\"training_data\", 45, droplet_labels)\n",
    "\n",
    "print(img_batch.shape, label_batch.shape)\n",
    "# show_batch(img_batch, label_batch, idx=31)\n",
    "\n",
    "img_batch = img_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a5bbb-cb3a-47b6-a89c-2481554d2451",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d54f30-dbd7-4aff-a901-b6486c2a8252",
   "metadata": {},
   "source": [
    "## 3 layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c1a42-2c09-4066-9b81-a7717e04c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=img_shape)\n",
    "\n",
    "conv1 = keras.layers.Conv2D(16, 4, padding='same', activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=None)(inputs)\n",
    "conv1 = keras.layers.BatchNormalization(momentum=0.99)(conv1)\n",
    "\n",
    "conv2 = keras.layers.Conv2D(32, 4, padding='same', activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=None)(conv1)\n",
    "conv2 = keras.layers.BatchNormalization(momentum=0.99)(conv2)\n",
    "\n",
    "conv3 = keras.layers.Conv2D(16, 4, padding='same', activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=None)(conv2)\n",
    "conv3 = keras.layers.BatchNormalization(momentum=0.99)(conv3)\n",
    "\n",
    "outputs = keras.layers.Conv2D(1, 4, padding='same', activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=None)(conv3)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebc5671-31d4-48ff-a692-751cac381a40",
   "metadata": {},
   "source": [
    "## Define a reduced mean square loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a575cc-ee39-4da6-b511-743d12a045cb",
   "metadata": {},
   "source": [
    "## Compile CNN optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae5a6c-af0a-472f-b287-e1a708052154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1ff19-929f-473d-9f98-809a4990dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "model.fit(img_batch, label_batch, batch_size=1500, epochs=1500, verbose=1)\n",
    "print(f\"Time taken = {int(time.time() - t1)} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6df9ba3-65a7-4325-ac21-7496a44503a6",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165385e4-ff16-4d6a-94b4-5f3ad2ee8baf",
   "metadata": {},
   "source": [
    "### Test data results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35bf493-5b58-4980-821c-d77db6303ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_batch(10, img_shape[0], img_shape[1])\n",
    "pred = model.predict(img_batch)\n",
    "\n",
    "fig = handler.show_result(img_batch, label_batch, pred)\n",
    "# fig.savefig(os.path.join(\"results\", \"test_data_result.png\"), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c84ce-90c7-43ab-8499-e57ea78b69f8",
   "metadata": {},
   "source": [
    "### Real data results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9b49d-d23f-4073-8667-e2bddcc7c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "i = 34\n",
    "images = sorted(os.listdir(\"training_data\"))\n",
    "img, label = handler.load_test_image(os.path.join(\"training_data\", images[i]), labels[i])\n",
    "pred = model.predict(img)\n",
    "\n",
    "handler.show_result(img, label, pred)\n",
    "# fig.savefig(os.path.join(\"results\", \"real_data_result.png\"), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d6a410-627b-4461-95bd-7e5685cfda0d",
   "metadata": {},
   "source": [
    "# Save model if training successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d466eac9-f2b5-47ae-bfde-06bb88370d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('droplet_detection_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_droplet",
   "language": "python",
   "name": "ml_droplet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
