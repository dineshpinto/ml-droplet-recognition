{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c263c90-0ffa-450a-a9d8-8aa95956b953",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import ipympl\n",
    "\n",
    "from tqdm import tqdm\n",
    "import image_handler as handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26a67b5-e1d7-466e-83b7-f0a310bf191f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"droplet_detection_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b63b3c99-6334-4f89-901e-152c884bbc3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "folder = \"training_data\"\n",
    "# folder = os.path.join(\"output_data\", \"basic\")\n",
    "\n",
    "images = []\n",
    "for file in os.listdir(folder):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        images.append(file)\n",
    "\n",
    "images = sorted(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ab85e1-1fd3-4f1c-b8fc-4fb0597935c7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Compare Neural network output with CV2 fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0cd27c9d-e4b4-4d64-9fe0-c54a41150fa8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t9_well3_4.jpg: : 102it [00:31,  3.27it/s] \n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(enumerate(images))\n",
    "\n",
    "num_circles_detected = 0\n",
    "\n",
    "for idx, image in pbar:\n",
    "    pbar.set_description(image)    \n",
    "    img = cv2.cvtColor(cv2.imread(os.path.join(\"training_data\", image)), cv2.COLOR_BGR2GRAY)\n",
    "    processed = img.copy()\n",
    "    \n",
    "    # processed = cv2.Canny(processed, 5, 70, 3)\n",
    "    #smooth to reduce noise a bit more\n",
    "    processed = cv2.GaussianBlur(processed, (5, 5), 0)\n",
    "    \n",
    "    circles = cv2.HoughCircles(processed, cv2.HOUGH_GRADIENT, 1, 50, param1=30, param2=30, minRadius=15, maxRadius=60)\n",
    "    \n",
    "    if circles is not None:\n",
    "        num_circles_detected += 1\n",
    "        \n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        \n",
    "        for (x, y, r) in circles:\n",
    "            cv2.circle(processed, center=(x, y), radius=r, color=(255, 255, 0), thickness=4)\n",
    "            cv2.rectangle(processed, pt1=(x-5, y-5), pt2=(x+5, y+5), color=(0, 128, 255), thickness=-1)\n",
    "\n",
    "    # cv2.imwrite(os.path.join(\"output_data\", \"circle_fitting\", image), output)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(15, 8), sharex=\"all\", sharey=\"all\")\n",
    "    \n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Neural Network Output\")\n",
    "    ax[1].imshow(processed, cmap=\"gray\")\n",
    "    ax[1].set_title(\"CV2 Circle Fit\")\n",
    "    \n",
    "    fig.savefig(os.path.join(\"output_data\", \"droplet_detection\", image), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ec09c515-6bd5-471b-99fa-c32d77ce81b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent detected 72.5%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percent detected {num_circles_detected / len(images) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3fdd6c-89dc-45bb-b229-281621c31405",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Overlay result on original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1fe87428-3340-46a2-9d58-ee1667be5d55",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t9_well3_4.jpg: : 102it [00:17,  5.79it/s] \n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(enumerate(images))\n",
    "\n",
    "num_circles_detected = 0\n",
    "\n",
    "for idx, image in pbar:\n",
    "    pbar.set_description(image) \n",
    "    \n",
    "    img_original, _, _= handler.load_image(\n",
    "        os.path.join(\"training_data\", image), \n",
    "        circle_label=None, \n",
    "        overlay=False, \n",
    "        scale_percent=30\n",
    "    )\n",
    "    \n",
    "    img = cv2.cvtColor(cv2.imread(os.path.join(\"output_data\", \"basic\", image)), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    processed = img.copy()\n",
    "    processed = cv2.GaussianBlur(processed, (5, 5), 0)\n",
    "    \n",
    "    circles = cv2.HoughCircles(processed, cv2.HOUGH_GRADIENT, 1, 50, param1=30, param2=30, minRadius=15, maxRadius=60)\n",
    "    \n",
    "    if circles is not None:\n",
    "        num_circles_detected += 1\n",
    "        \n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        \n",
    "        for (x, y, r) in circles:\n",
    "            cv2.circle(img_original, center=(x, y), radius=r, color=(255, 255, 0), thickness=4)\n",
    "            cv2.rectangle(processed, pt1=(x-5, y-5), pt2=(x+5, y+5), color=(0, 128, 255), thickness=-1)\n",
    "\n",
    "    # cv2.imwrite(os.path.join(\"output_data\", \"circle_fitting\", image), output)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.imshow(img_original, cmap=\"gray\")\n",
    "    ax.set_title(\"Neural Network Output\")\n",
    "    \n",
    "    fig.savefig(os.path.join(\"output_data\", \"droplet_detection\", image), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "86207233-7a28-4c42-9ce8-644d9016182c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent detected 72.5%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percent detected {num_circles_detected / len(images) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb10f561-0e9c-44f7-94b5-9f69145f3fa5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Save basic images (no axes etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae630b93-bc1b-42ac-a48b-fa57ae9203f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t9_well3_4.jpg: : 102it [00:02, 38.17it/s] \n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(enumerate(images))\n",
    "for idx, image in pbar:\n",
    "    pbar.set_description(image)\n",
    "    img, _ = handler.load_test_image(os.path.join(folder, image), circle_label=None, scale_percent=100)\n",
    "    pred = model.predict(img)\n",
    "    cv2.imwrite(os.path.join(\"output_data\", \"two_run\", image), pred[0, :, :, :] * 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412395c8-d201-4ba5-bea3-c5f25044b86d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Compare with input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44e9ebe6-6ef6-4c54-a3c0-32946d6de36d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t0_well0_0.jpg: : 0it [00:00, ?it/s]2022-04-26 23:40:19.581365: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "t9_well3_4.jpg: : 102it [00:15,  6.69it/s] \n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(enumerate(images))\n",
    "for idx, image in pbar:\n",
    "    pbar.set_description(image)\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, sharex=\"all\", sharey=\"all\", figsize=(10, 7))\n",
    "\n",
    "    img, _ = handler.load_test_image(os.path.join(\"training_data\", image), circle_label=None)\n",
    "    pred = model.predict(img)\n",
    "\n",
    "    ax[0].imshow(img[0, :, :, :], cmap=\"gray\")\n",
    "    ax[0].set_title(\"Experimental Data\")\n",
    "    ax[1].imshow(pred[0, :, :, :], cmap=\"gray\")\n",
    "    ax[1].set_title(\"Neural Network\")\n",
    "    \n",
    "    fig.savefig(os.path.join(\"output_data\", \"compare\", image), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991e711c-986b-434b-a5f5-7aaa23213e45",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# General model layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750fa302-54a6-4f84-beed-6e7888f8c473",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, to_file=os.path.join(\"results\", \"model.png\"), show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_droplet",
   "language": "python",
   "name": "ml_droplet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}